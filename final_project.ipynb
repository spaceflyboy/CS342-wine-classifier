{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849a57cd",
   "metadata": {},
   "source": [
    "# CS 342 Neural Nets: Final Project\n",
    "\n",
    "Authors: Ryan Gahagan (rg32643) and Dustan Helm (dbh878)\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this project, we will create a neural network that will hopefully be able to predict the quality of various wines given their chemical compositions.\n",
    "\n",
    "This project's data set and idea are based off another paper, cited here:\n",
    "\n",
    "  \"P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "  \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  \n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\"\n",
    "\n",
    "We plan to make a feed-forward network to process this data, as well as some experiments to test and analyze our network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51836a78",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "First, we have to take the data set and process it into a format that Python can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60be6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to load important libraries and set things up\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb994c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in dataset files\n",
    "white_file = open(\"winequality-white-nolabels.csv\")\n",
    "wine_quality_white = np.loadtxt(white_file, delimiter=\";\")\n",
    "red_file = open(\"winequality-red-nolabels.csv\")\n",
    "wine_quality_red = np.loadtxt(red_file, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b4d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_quality_combined_whitered.shape = (6497, 12)\n"
     ]
    }
   ],
   "source": [
    "# Create suitable data_arrays\n",
    "num_samples_white = wine_quality_white.shape[0]\n",
    "num_samples_red = wine_quality_red.shape[0]\n",
    "num_samples_total = num_samples_white + num_samples_red\n",
    "\n",
    "# Combine white and red wine datasets into one np array\n",
    "wine_quality_combined_whitered = np.append(wine_quality_white, wine_quality_red, axis=0)\n",
    "\n",
    "print(f\"wine_quality_combined_whitered.shape = {wine_quality_combined_whitered.shape}\")\n",
    "\n",
    "assert wine_quality_combined_whitered.shape[0] == num_samples_total\n",
    "\n",
    "# Rename\n",
    "data_array = wine_quality_combined_whitered\n",
    "data_array_white = wine_quality_white\n",
    "data_array_red = wine_quality_red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c0585",
   "metadata": {},
   "source": [
    "Now we've loaded our datasets into lists. `data_array_red` is an `np.array` whose shape is `(1599,12)` and `data_array_white` is likewise an array of shape `(4898,12)`. `data_array` is simply those two arrays concatenated into an array of shape `(6497,12)`.\n",
    "\n",
    "Note that these 12 columns represent both features and labels.\n",
    "\n",
    "The columns, in order, are:\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides\n",
    "- free sulfur dioxide\n",
    "- total sulfur dioxide\n",
    "- density\n",
    "- pH\n",
    "- sulphates\n",
    "- alcohol\n",
    "- quality (integer in \\[0,10\\])\n",
    "where quality is our label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72913e5b",
   "metadata": {},
   "source": [
    "## Data Breakdown\n",
    "\n",
    "Before we process the data into a more pytorch-friendly form, here's a breakdown of the range and averages of each dataset's 11 features. \n",
    "\n",
    "You can run the cell directly below this one to show the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fa9702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min, Max, Average Information for Dataset #1/3:\n",
      "Feature #1/11: (Min, Max) = (3.8, 15.9), avg = 7.215307064799138\n",
      "Feature #2/11: (Min, Max) = (0.08, 1.58), avg = 0.33966599969216565\n",
      "Feature #3/11: (Min, Max) = (0.0, 1.66), avg = 0.3186332153301524\n",
      "Feature #4/11: (Min, Max) = (0.6, 65.8), avg = 5.443235339387409\n",
      "Feature #5/11: (Min, Max) = (0.009, 0.611), avg = 0.05603386178236109\n",
      "Feature #6/11: (Min, Max) = (1.0, 289.0), avg = 30.525319378174544\n",
      "Feature #7/11: (Min, Max) = (6.0, 440.0), avg = 115.7445744189626\n",
      "Feature #8/11: (Min, Max) = (0.98711, 1.03898), avg = 0.9946966338309989\n",
      "Feature #9/11: (Min, Max) = (2.72, 4.01), avg = 3.2185008465445586\n",
      "Feature #10/11: (Min, Max) = (0.22, 2.0), avg = 0.5312682776666153\n",
      "Feature #11/11: (Min, Max) = (8.0, 14.9), avg = 10.491800831152778\n",
      "Min, Max, Average Information for Dataset #2/3:\n",
      "Feature #1/11: (Min, Max) = (3.8, 14.2), avg = 6.854787668436097\n",
      "Feature #2/11: (Min, Max) = (0.08, 1.1), avg = 0.27824111882400976\n",
      "Feature #3/11: (Min, Max) = (0.0, 1.66), avg = 0.33419150673744386\n",
      "Feature #4/11: (Min, Max) = (0.6, 65.8), avg = 6.391414863209474\n",
      "Feature #5/11: (Min, Max) = (0.009, 0.346), avg = 0.04577235606369946\n",
      "Feature #6/11: (Min, Max) = (2.0, 289.0), avg = 35.30808493262556\n",
      "Feature #7/11: (Min, Max) = (9.0, 440.0), avg = 138.36065741118824\n",
      "Feature #8/11: (Min, Max) = (0.98711, 1.03898), avg = 0.9940273764801959\n",
      "Feature #9/11: (Min, Max) = (2.72, 3.82), avg = 3.1882666394446715\n",
      "Feature #10/11: (Min, Max) = (0.22, 1.08), avg = 0.48984687627603113\n",
      "Feature #11/11: (Min, Max) = (8.0, 14.2), avg = 10.514267047774519\n",
      "Min, Max, Average Information for Dataset #3/3:\n",
      "Feature #1/11: (Min, Max) = (4.6, 15.9), avg = 8.31963727329581\n",
      "Feature #2/11: (Min, Max) = (0.12, 1.58), avg = 0.5278205128205128\n",
      "Feature #3/11: (Min, Max) = (0.0, 1.0), avg = 0.2709756097560976\n",
      "Feature #4/11: (Min, Max) = (0.9, 15.5), avg = 2.53880550343965\n",
      "Feature #5/11: (Min, Max) = (0.012, 0.611), avg = 0.08746654158849279\n",
      "Feature #6/11: (Min, Max) = (1.0, 72.0), avg = 15.874921826141339\n",
      "Feature #7/11: (Min, Max) = (6.0, 289.0), avg = 46.46779237023139\n",
      "Feature #8/11: (Min, Max) = (0.99007, 1.00369), avg = 0.9967466791744841\n",
      "Feature #9/11: (Min, Max) = (2.74, 4.01), avg = 3.3111131957473416\n",
      "Feature #10/11: (Min, Max) = (0.33, 2.0), avg = 0.6581488430268917\n",
      "Feature #11/11: (Min, Max) = (8.4, 14.9), avg = 10.422983114446529\n"
     ]
    }
   ],
   "source": [
    "start_ends = []\n",
    "start_ends_white = []\n",
    "start_ends_red = []\n",
    "\n",
    "avgs = []\n",
    "avgs_white = []\n",
    "avgs_red = []\n",
    "\n",
    "datasets = [data_array, data_array_white, data_array_red]\n",
    "averages = [avgs, avgs_white, avgs_red]\n",
    "start_ends_list = [start_ends, start_ends_white, start_ends_red]\n",
    "\n",
    "for i in range(3):\n",
    "    data_arr = datasets[i]\n",
    "    avgs_arr = averages[i]\n",
    "    start_ends_arr = start_ends_list[i]\n",
    "    print(f\"Min, Max, Average Information for Dataset #{i+1}/3:\")\n",
    "    for j in range(11):\n",
    "        start = np.amin(data_arr[:,j])\n",
    "        end = np.amax(data_arr[:,j])\n",
    "        avg = np.average(data_arr[:,j])\n",
    "        start_ends_arr.append((start, end))\n",
    "        avgs_arr.append(avg)\n",
    "        print(f\"Feature #{j+1}/11: (Min, Max) = {start_ends_arr[j]}, avg = {avgs_arr[j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd608f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data array into features and label arrays\n",
    "# Inputs: \n",
    "#     data_array: Data array to be split into features and labels\n",
    "# Outputs:\n",
    "#     data_array_feats: Features for data_array\n",
    "#     data_array_labels: Labels for data_array\n",
    "def split_features_labels(data_array):\n",
    "    assert isinstance(data_array, np.ndarray)\n",
    "    #assert data_array.shape[1] == 12\n",
    "    \n",
    "    data_array_feats = data_array[:,:-1] # first 11 columns\n",
    "    data_array_labels = data_array[:,-1] # last column\n",
    "\n",
    "    #assert data_array_feats.shape[1] == 11\n",
    "    assert data_array_feats.shape[0] == data_array_labels.shape[0]\n",
    "    \n",
    "    return data_array_feats, data_array_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e892a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data array into training and testing sets based on the provided train_proportion parameter\n",
    "# Inputs: \n",
    "#     data_array: Dataset to split for training and testing\n",
    "#     train_proportion: Proportion of datapoints to be kept as training data\n",
    "# Outputs:\n",
    "#     train_set: Training set containing a proportion of the datapoints contained in data_array specified by input parameter.\n",
    "#     test_set: Testing set containing held-back datapoints to test the trained model\n",
    "def train_test_split(data_array, train_proportion):\n",
    "    assert isinstance(data_array, np.ndarray)\n",
    "    #assert data_array.shape[1] == 12\n",
    "    \n",
    "    num_samples = data_array.shape[0]\n",
    "    \n",
    "    feats, labels = split_features_labels(data_array)\n",
    "    data_set = torch.utils.data.TensorDataset(torch.tensor(feats), torch.tensor(labels).long())\n",
    "    \n",
    "    train_size = int(train_proportion*num_samples)\n",
    "    test_size = num_samples - train_size\n",
    "    \n",
    "    train_set, test_set = torch.utils.data.random_split(data_set, [train_size, test_size])\n",
    "    \n",
    "    assert abs(len(train_set) / len(data_array) - train_proportion) < 0.01\n",
    "    assert abs(len(test_set) / len(data_array)  - (1 - train_proportion)) < 0.01\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a870039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the actual split on all of our datasets into training and testing\n",
    "train_proportion = 0.8\n",
    "train_proportion_white = 0.8\n",
    "train_proportion_red = 0.8\n",
    "\n",
    "train_set, test_set = train_test_split(data_array, train_proportion)\n",
    "train_set_white, test_set_white = train_test_split(data_array_white, train_proportion_white)\n",
    "train_set_red, test_set_red = train_test_split(data_array_red, train_proportion_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35420ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set into true training and validation data based on the input proportion\n",
    "# Inputs:\n",
    "#     ntotal: Total number of datapoints in the original training set to be used to determine the split\n",
    "#     train_proportion: Proportion of the training set examples which should not be placed into the validation set\n",
    "# Outputs:\n",
    "#     train_ix: Indices for training examples\n",
    "#     val_ix: Indices for validation examples\n",
    "\n",
    "def train_val_split_ix(ntotal, train_proportion):\n",
    "    ntrain = int(train_proportion*ntotal)\n",
    "    nval = ntotal - ntrain\n",
    "    \n",
    "    val_ix = np.random.choice(range(ntotal), size=nval, replace=False)\n",
    "    train_ix = list(set(range(ntotal)) - set(val_ix))\n",
    "    \n",
    "    assert abs(len(train_ix) / ntotal - train_proportion) < 0.01\n",
    "    assert abs(len(val_ix) / ntotal - (1 - train_proportion)) < 0.01\n",
    "    \n",
    "    return (train_ix, val_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb14a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(len(train_ix), len(val_ix)) = (4677, 520)\n",
      "(len(train_white_ix), len(val_white_ix)) = (3526, 392)\n",
      "(len(train_red_ix), len(val_red_ix)) = (1151, 128)\n"
     ]
    }
   ],
   "source": [
    "# Perform the training/validation split and then confirm array lengths\n",
    "train_proportion2 = 0.9\n",
    "train_proportion_white2 = 0.9\n",
    "train_proportion_red2 = 0.9\n",
    "\n",
    "train_ix, val_ix = train_val_split_ix(len(train_set), train_proportion2)\n",
    "train_white_ix, val_white_ix = train_val_split_ix(len(train_set_white), train_proportion_white2)\n",
    "train_red_ix, val_red_ix = train_val_split_ix(len(train_set_red), train_proportion_red2)\n",
    "\n",
    "print(f\"(len(train_ix), len(val_ix)) = ({len(train_ix)}, {len(val_ix)})\")\n",
    "print(f\"(len(train_white_ix), len(val_white_ix)) = ({len(train_white_ix)}, {len(val_white_ix)})\")\n",
    "print(f\"(len(train_red_ix), len(val_red_ix)) = ({len(train_red_ix)}, {len(val_red_ix)})\")\n",
    "\n",
    "assert len(train_ix) + len(val_ix) == len(train_set)\n",
    "assert len(train_white_ix) + len(val_white_ix) == len(train_set_white)\n",
    "assert len(train_red_ix) + len(val_red_ix) == len(train_set_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e44ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data samplers for use in DataLoader objects\n",
    "# Inputs: \n",
    "#     datalist_ix: Tuple of index lists used to determine each loader's data\n",
    "# Outputs:\n",
    "#     result: Tuple of SubsetRandomSamplers representing each index list object in datalist_ix\n",
    "def setup_samplers(datalist_ix):\n",
    "    result = ()\n",
    "    for data_ix in datalist_ix:\n",
    "        result += (SubsetRandomSampler(data_ix),)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adf04a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a tuple of Data Loaders based on provided datasets, samplers, and batch_size\n",
    "# Inputs:\n",
    "#     datalist: List of datasets to give to the DataLoaders\n",
    "#     samplers: List of samplers to use in the DataLoaders\n",
    "#     batch_size: DataLoader batch size (Currently uses the same batch_size for every dataset passed)\n",
    "# Outputs:\n",
    "#     Tuple of DataLoader objects len(datalist) size long \n",
    "def setup_data_loaders(datalist, samplers, batch_size):\n",
    "    assert len(datalist) == len(samplers)\n",
    "    \n",
    "    result = ()\n",
    "    for i in range(len(datalist)):\n",
    "        data = datalist[i]\n",
    "        sampler = samplers[i]\n",
    "        result += (torch.utils.data.DataLoader(data, batch_size, sampler=sampler),)\n",
    "    return result\n",
    "\n",
    "#TODO: It may be useful to have different batch_size values for training, validation, and testing. \n",
    "# In that event, batch_size should be replaced with a touple of batch_size values and the following should be added to the loop:\n",
    "# batch_size = batch_sizes[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f05333",
   "metadata": {},
   "source": [
    "Now that we've declared methods to do various helper tasks, we're going to actually break our data into useful information.\n",
    "\n",
    "The three sets of data (red, white, and combined) will be each partitioned into a training set, a validation set, and a testing set (whose sizes will be proportional to the variables declared above). We will then create `DataLoader` objects for each of these partitions so that we can iterate over them in our training section.\n",
    "\n",
    "Note here that we also declare batch sizes to determine how many pieces of information are trained on at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ca66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up samplers and DataLoaders for all three datasets (Combined, White, Red)\n",
    "batch_size = 100\n",
    "batch_size_white = 100\n",
    "batch_size_red = 100\n",
    "\n",
    "#COMBINED DATASET\n",
    "sampler_input = (train_ix, val_ix)\n",
    "train_sampler, val_sampler = setup_samplers(sampler_input)\n",
    "\n",
    "datalist = (train_set, train_set, test_set)\n",
    "samplers = (train_sampler, val_sampler, None)\n",
    "train_loader, val_loader, test_loader = setup_data_loaders(datalist, samplers, batch_size)\n",
    "\n",
    "#JUST WHITE\n",
    "sampler_input_white = (train_white_ix, val_white_ix)\n",
    "train_sampler_white, val_sampler_white = setup_samplers(sampler_input_white)\n",
    "\n",
    "datalist_white = (train_set_white, train_set_white, test_set_white)\n",
    "samplers_white = (train_sampler_white, val_sampler_white, None)\n",
    "train_loader_white, val_loader_white, test_loader_white = setup_data_loaders(datalist_white, samplers_white, batch_size_white)\n",
    "\n",
    "#JUST RED\n",
    "sampler_input_red = (train_red_ix, val_red_ix)\n",
    "train_sampler_red, val_sampler_red = setup_samplers(sampler_input_red)\n",
    "\n",
    "datalist_red = (train_set_red, train_set_red, test_set_red)\n",
    "samplers_red = (train_sampler_red, val_sampler_red, None)\n",
    "train_loader_red, val_loader_red, test_loader_red = setup_data_loaders(datalist_red, samplers_red, batch_size_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e47e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-splits the data into new random chunks to help reduce noise\n",
    "#\n",
    "# Inputs: data_arrays for combined data set, white wine dataset, and red dataset to generate loaders from\n",
    "# Outputs:\n",
    "#    A list [full, white, red] of loader tuples (train, val, test)\n",
    "def get_random_loaders(data_array, data_array_white, data_array_red):\n",
    "    batch_size = 100\n",
    "    batch_size_white = 100\n",
    "    batch_size_red = 100\n",
    "    \n",
    "    # Get train/test sets\n",
    "    train_set, test_set = train_test_split(data_array, train_proportion)\n",
    "    train_set_white, test_set_white = train_test_split(data_array_white, train_proportion_white)\n",
    "    train_set_red, test_set_red = train_test_split(data_array_red, train_proportion_red)\n",
    "    \n",
    "    # Get train/val indices\n",
    "    train_ix, val_ix = train_val_split_ix(len(train_set), train_proportion2)\n",
    "    train_white_ix, val_white_ix = train_val_split_ix(len(train_set_white), train_proportion_white2)\n",
    "    train_red_ix, val_red_ix = train_val_split_ix(len(train_set_red), train_proportion_red2)\n",
    "    \n",
    "    #COMBINED DATASET\n",
    "    sampler_input = (train_ix, val_ix)\n",
    "    train_sampler, val_sampler = setup_samplers(sampler_input)\n",
    "\n",
    "    datalist = (train_set, train_set, test_set)\n",
    "    samplers = (train_sampler, val_sampler, None)\n",
    "    train_loader, val_loader, test_loader = setup_data_loaders(datalist, samplers, batch_size)\n",
    "\n",
    "    #JUST WHITE\n",
    "    sampler_input_white = (train_white_ix, val_white_ix)\n",
    "    train_sampler_white, val_sampler_white = setup_samplers(sampler_input_white)\n",
    "\n",
    "    datalist_white = (train_set_white, train_set_white, test_set_white)\n",
    "    samplers_white = (train_sampler_white, val_sampler_white, None)\n",
    "    train_loader_white, val_loader_white, test_loader_white = setup_data_loaders(datalist_white, samplers_white, batch_size_white)\n",
    "\n",
    "    #JUST RED\n",
    "    sampler_input_red = (train_red_ix, val_red_ix)\n",
    "    train_sampler_red, val_sampler_red = setup_samplers(sampler_input_red)\n",
    "\n",
    "    datalist_red = (train_set_red, train_set_red, test_set_red)\n",
    "    samplers_red = (train_sampler_red, val_sampler_red, None)\n",
    "    train_loader_red, val_loader_red, test_loader_red = setup_data_loaders(datalist_red, samplers_red, batch_size_red)\n",
    "    \n",
    "    return [(train_loader, val_loader, test_loader), \\\n",
    "           (train_loader_white, val_loader_white, test_loader_white), \\\n",
    "           (train_loader_red, val_loader_red, test_loader_red)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96077d94",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "With our data processed and ready to be used, now we will write some functions to train and test a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd3f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the provided model with data gathered from train_loader, the given criterion, and the given optimizer.\n",
    "# Additionally perform validation checks with data from val_loader.\n",
    "# Inputs:\n",
    "#     model: Neural network to train\n",
    "#     train_loader: DataLoader which provides training data to the model \n",
    "#     val_loader: DataLoader which provides validation data to the model\n",
    "#     criterion: Loss Function which trains the model\n",
    "#     optimizer: Optimization algorithm to improve loss during training \n",
    "#     nepoch: Number of epochs to train for (Defaults to 100)\n",
    "# Outputs:\n",
    "#     Prints the Training and Validation loss at each epoch\n",
    "def train_network(model, train_loader, val_loader, criterion, optimizer, nepoch=100,silent=True):\n",
    "    try:\n",
    "        cur_range = None\n",
    "        if silent:\n",
    "            cur_range = range(nepoch)\n",
    "        else:\n",
    "            cur_range = tqdm(range(nepoch))\n",
    "\n",
    "        for epoch in cur_range:\n",
    "            # Train over each epoch with a progress bar (tqdm)\n",
    "            if not silent: \n",
    "                print('EPOCH %d'%epoch)\n",
    "            \n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                # For each train input: \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward propagate inputs\n",
    "                outputs = model.forward(inputs)\n",
    "                \n",
    "                # Compute loss and learn\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Add current loss to batch average\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "            \n",
    "            # Show Training loss for current epoch over the train_loader data\n",
    "            if not silent:\n",
    "                print('{:>12s} {:>7.5f}'.format('Train loss:', total_loss/count))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Perform Validation checks on the newly trained model\n",
    "                total_loss = 0\n",
    "                count = 0\n",
    "                for inputs, labels in val_loader:\n",
    "                    # Forward propagate inputs\n",
    "                    outputs = model.forward(inputs)\n",
    "                    \n",
    "                    # Compute Loss\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Add current loss to batch average\n",
    "                    total_loss += loss.item()\n",
    "                    count += 1\n",
    "                    \n",
    "                # Show Validation loss for current epoch over the val_loader data\n",
    "                if not silent:\n",
    "                    print('{:>12s} {:>7.5f}'.format('Val loss:', total_loss/count))\n",
    "                    print()\n",
    "    except KeyboardInterrupt as e:\n",
    "        print('Exiting from training early')\n",
    "        raise e\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c21a1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the provided model with data from test_loader\n",
    "# Inputs:\n",
    "#     model: Model to test using unseen data\n",
    "#     test_loader: DataLoader to provide held-back testing data to trained model\n",
    "#     mode: String used at front of each loss printout\n",
    "# Outputs:\n",
    "#     acc: Top-1 accuracy of the model on the testing data in percent\n",
    "#     true: Array of actual labels\n",
    "#     pred: Array of model-predicted labels\n",
    "def test_network(model, test_loader, mode=\"test_network\", silent=True):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true, pred = [], []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for inputs, labels  in test_loader:\n",
    "            # Forward propagate testing data\n",
    "            outputs = model.forward(inputs)\n",
    "            \n",
    "            # Get the prediction for inputs\n",
    "            vals, predicted = torch.max(outputs, dim=1) \n",
    "            \n",
    "            # Tally results \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            true.append(labels)\n",
    "            pred.append(predicted)\n",
    "    \n",
    "    # Compute and print final accuracy, then format outputs\n",
    "    acc = (100 * correct / total)\n",
    "    if not silent:\n",
    "        print('%s accuracy: %0.3f' % (mode, acc))\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    return acc, true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b5ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single method to wrap all of training and testing\n",
    "#\n",
    "# Inputs:\n",
    "#   Positional:\n",
    "#     model: the model to train/test (should be newly initialized)\n",
    "#     train_loader: DataLoader for training set\n",
    "#     val_loader: DataLoader for validation set\n",
    "#     test_loader: DataLoader for testing set\n",
    "#     criterion: loss function (e.g. CrossEntropyLoss)\n",
    "#     optimizer: optimizing function (e.g. Adam)\n",
    "#   kwargs (keyword):\n",
    "#     nepoch: number of epochs, defaults to 100\n",
    "#     mode: string to print during test, defaults to \"Model\"\n",
    "#     train_silent: boolean to silence training, defaults to True\n",
    "#     test_silent: boolean to silence testing, defaults to True\n",
    "# Outputs:\n",
    "#     acc: accuracy of testing, in range (0, 100)\n",
    "#     true: list of true labels\n",
    "#     pred: list of predicted labels\n",
    "def train_and_test(model, train_loader, val_loader, test_loader, criterion, \\\n",
    "                   optimizer, **kwargs):\n",
    "    # Get keyword args, and default missing\n",
    "    nepoch = kwargs.get(\"nepoch\", 100)\n",
    "    mode = kwargs.get(\"mode\", \"Model\")\n",
    "    train_silent = kwargs.get(\"train_silent\", True)\n",
    "    test_silent = kwargs.get(\"test_silent\", True)\n",
    "    try:\n",
    "        train_network(model, train_loader, val_loader, criterion, optimizer, nepoch, train_silent)\n",
    "    except KeyboardInterrupt as e:\n",
    "        print(\"train_and_test: Keyboard Interrupt detected, raising an exception\")\n",
    "        raise e\n",
    "    model.eval()\n",
    "    acc, true, pred = test_network(model, test_loader, mode, test_silent)\n",
    "    return acc, true, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cc903",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "With our training and testing functionality equipped, now we will actually decide how to build our model.\n",
    "\n",
    "Note here that there will be a heavy focus on making the model flexible so that we can tune hyperparameters or test new input varieties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325ac4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WineQualityModel(torch.nn.Module):\n",
    "    # Constructor for a WineQualityModel\n",
    "    # Inputs:\n",
    "    #     layers: a tuple of layers that you want in the model\n",
    "    #       note that the output shape must be of length 10\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "\n",
    "        # NOTE: this gives the construction tons of flexibility\n",
    "        # but also leaves plenty of room for dimensionality errors\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers.forward(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f3df1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model accuracy: 53.154\n",
      "White Model accuracy: 50.408\n",
      "Red Model accuracy: 57.812\n"
     ]
    }
   ],
   "source": [
    "model = WineQualityModel((\n",
    "    torch.nn.Linear(11, 81),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(81, 11)\n",
    "))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_and_test(model, train_loader, val_loader, test_loader, criterion, \\\n",
    "               optimizer, mode=\"Combined Model\", test_silent=False)\n",
    "\n",
    "model_white = WineQualityModel((\n",
    "    torch.nn.Linear(11, 81),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(81, 11)\n",
    "))\n",
    "\n",
    "optimizer_white = torch.optim.Adam(model_white.parameters(), lr=1e-3)\n",
    "train_and_test(model_white, train_loader_white, val_loader_white, test_loader_white, \\\n",
    "               criterion, optimizer_white, mode=\"White Model\", test_silent=False)\n",
    "\n",
    "model_red = WineQualityModel((\n",
    "    torch.nn.Linear(11, 81),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(81, 11)\n",
    "))\n",
    "\n",
    "optimizer_red = torch.optim.Adam(model_red.parameters(), lr=1e-3)\n",
    "_, _, _ = train_and_test(model_red, train_loader_red, val_loader_red, test_loader_red, \\\n",
    "                         criterion, optimizer_red, mode=\"Red Model\", test_silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b295cf7",
   "metadata": {},
   "source": [
    "## Hypertuning\n",
    "\n",
    "Now that we have the ability to initialize and train a model, we're going to try hypertuning some of the parameters. Specifically we want to try tuning the number of layers and the hidden size of each of those layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b4ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of layers, creates a model that fits that specification\n",
    "# then trains and tests it, all in one method. There are actually three\n",
    "# models of identical specification constructed and trained separately,\n",
    "# and their results are likewise returned piecewise.\n",
    "#\n",
    "# Inputs:\n",
    "#     layers: a tuple of all the layers you want in your model\n",
    "# Outputs:\n",
    "#     true_lists: a tuple of lists of all the actual labels per dataset\n",
    "#                 in the order (full, white, red)\n",
    "#     pred_lists: a tuple of lists of model predictions per model/dataset\n",
    "#                 in the order (full, white, red)\n",
    "def create_and_report_model(layers, nepoch=250):\n",
    "    assert len(layers) > 0\n",
    "    \n",
    "    # Check that you start and end with Linears\n",
    "    assert isinstance(layers[0], torch.nn.Linear)\n",
    "    assert isinstance(layers[-1], torch.nn.Linear)\n",
    "    \n",
    "    # Check that first layer takes in 11\n",
    "    # we may need to remove this during computational experiments\n",
    "    assert layers[0].weight.shape[1] == 11\n",
    "    \n",
    "    # Check that final layer outputs 11\n",
    "    assert layers[-1].weight.shape[0] == 11\n",
    "    \n",
    "    loaders = get_random_loaders(data_array, data_array_white, data_array_red)\n",
    "\n",
    "    true_lists = []\n",
    "    pred_lists = []\n",
    "    for i in range(3):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        cur_loaders = loaders[i]\n",
    "        cur_model = WineQualityModel(layers)\n",
    "        optimizer = torch.optim.Adam(cur_model.parameters(), lr=1e-3)\n",
    "        try:\n",
    "            acc, true, pred = train_and_test(cur_model, *cur_loaders, criterion, \\\n",
    "                                         optimizer, nepoch=nepoch, mode=f\"Model {i}\")\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"create_and_report_model. Training ended early. Raising an exception\")\n",
    "            raise e\n",
    "        \n",
    "        true_lists.append(true)\n",
    "        pred_lists.append(pred)\n",
    "\n",
    "    return true_lists, pred_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f098d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the accuracy of a prediction list compared to a true list\n",
    "# Measures two accuracies: exact accuracy, and tolerance 1 accuracy\n",
    "#\n",
    "# Inputs:\n",
    "#     true: a list of actual labels\n",
    "#     pred: a list of predicted labels\n",
    "# Outputs:\n",
    "#     exact_acc: percentage (in range (0,100)) of exact matches\n",
    "#     t1_acc: percentage (range of (0,100)) of 1-tolerance matches\n",
    "def compute_model_accuracies(true, pred):\n",
    "    assert len(true) == len(pred)\n",
    "    \n",
    "    num_exact = 0\n",
    "    num_1_tolerant = 0\n",
    "    \n",
    "    for i in range(len(true)):\n",
    "        t = true[i]\n",
    "        p = pred[i]\n",
    "        \n",
    "        if t == p:\n",
    "            # Exact match\n",
    "            num_exact += 1\n",
    "\n",
    "        if abs(t - p) <= 1:\n",
    "            # Within one (e.g. 6,7,8 are all within 1 of 7)\n",
    "            num_1_tolerant += 1\n",
    "    \n",
    "    exact_acc = num_exact / len(true)\n",
    "    t1_acc = num_1_tolerant / len(true)\n",
    "    return 100 * exact_acc, 100 * t1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14b110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full accuracies (exact, T1):\n",
      "(52.84615384615384, 94.84615384615384)\n",
      "\n",
      "White accuracy:\n",
      "(55.61224489795919, 96.0204081632653)\n",
      "\n",
      "Red accuracy:\n",
      "(64.0625, 95.3125)\n"
     ]
    }
   ],
   "source": [
    "# Example of how we might train everything\n",
    "true_lists, pred_lists = create_and_report_model((\n",
    "    torch.nn.Linear(11,49,bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.Linear(49,11,bias=False),\n",
    "))\n",
    "print(\"Full accuracies (exact, T1):\")\n",
    "print(compute_model_accuracies(true_lists[0], pred_lists[0]))\n",
    "print(\"\\nWhite accuracy:\")\n",
    "print(compute_model_accuracies(true_lists[1], pred_lists[1]))\n",
    "print(\"\\nRed accuracy:\")\n",
    "print(compute_model_accuracies(true_lists[2], pred_lists[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0f9ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big ol' wrapper over the whole tuning test\n",
    "# Just pass in the layers you want to test, and it'll spit out\n",
    "# the accuracy of that tuning on all three datasets\n",
    "#\n",
    "# Inputs:\n",
    "#     layers: layers of your model (tuple)\n",
    "# Ouputs:\n",
    "#     accuracies: list of 3 tuples, where each tuple holds the accuracies\n",
    "#                 i.e. (exact_acc, t1_acc) as percentage from 0 to 100\n",
    "def test_tuning(layers, nepoch=250):\n",
    "    num_noise_tests = 3\n",
    "    accuracies = [[0, 0], [0, 0], [0,0]]\n",
    "    for i in range(num_noise_tests):\n",
    "        try:\n",
    "            true_lists, pred_lists = create_and_report_model(layers, nepoch)\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"test_tuning: Training ended early due to keyboard interrupt. Raising an exception\")\n",
    "            raise e\n",
    "\n",
    "        for j in range(3):\n",
    "            cur_accs = compute_model_accuracies(true_lists[j], pred_lists[j])\n",
    "            accuracies[j][0] += cur_accs[0]\n",
    "            accuracies[j][1] += cur_accs[1]\n",
    "            \n",
    "    for i in range(len(accuracies)):\n",
    "        accuracies[i][0] /= num_noise_tests\n",
    "        accuracies[i][1] /= num_noise_tests\n",
    "        accuracies[i] = tuple(accuracies[i])\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "# The previous cell can now be written simply as:\n",
    "# accs = test_tuning((... layers))\n",
    "# You can use these accuracy tuples to print columns in a csv or smth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3cd6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns the accuracy list into a usable string\n",
    "# TODO: make thsi return your string in a way you actually\n",
    "# can use in a csv or whatever we want\n",
    "#\n",
    "# Inputs:\n",
    "#     accs: a list of tuple pairs representing the accuracies\n",
    "# Outputs:\n",
    "#     acc_str: a usable string representation of the accuracies\n",
    "#              cur format is [(full_exact, full_t1),(w_e,w_t),(r_e,r_t)]\n",
    "def get_accuracies_string(accs):\n",
    "    assert len(accs) == 3\n",
    "    assert len(accs[0]) == 2\n",
    "    assert len(accs[1]) == 2\n",
    "    assert len(accs[2]) == 2\n",
    "    \n",
    "    acc_str = \"[\"\n",
    "    for i in range(3):\n",
    "        acc_str += (\"(%0.2f,%0.2f)\" % (accs[i][0], accs[i][1]))\n",
    "        if i != 2:\n",
    "            acc_str += \",\"\n",
    "    return acc_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90eadd",
   "metadata": {},
   "source": [
    "Now we've got plenty of methods to reduce the complexity of our hypertuning loops, so all that's left is to actually write then in a readable way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c271b3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive accuracies [(full_exact, full_t1), (white_exact, white_t1), (red_exact, red_t1)]:\n",
      "[(52.92,94.15),(52.45,94.18),(52.50,95.62)\n"
     ]
    }
   ],
   "source": [
    "# Here's a boring naive single layer test\n",
    "accs = test_tuning(\n",
    "    (torch.nn.Linear(11, 11, bias=False),) # super important comma\n",
    ")\n",
    "print(\"Naive accuracies [(full_exact, full_t1), (white_exact, white_t1), (red_exact, red_t1)]:\")\n",
    "print(get_accuracies_string(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df4d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(54.31,94.15),(53.27,95.00),(55.62,96.56)\n",
      "[(55.23,95.23),(55.10,95.41),(55.62,95.94)\n"
     ]
    }
   ],
   "source": [
    "accs = test_tuning((\n",
    "    torch.nn.Linear(11, 40, bias=True),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(40, 11, bias=False),\n",
    "))\n",
    "print(get_accuracies_string(accs))\n",
    "\n",
    "accs = test_tuning((\n",
    "    torch.nn.Linear(11, 40, bias=True),\n",
    "    torch.nn.Dropout(0.3),\n",
    "    torch.nn.BatchNorm1d(40),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(40, 11, bias=False),\n",
    "))\n",
    "print(get_accuracies_string(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc10042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get loopy\n",
    "\n",
    "# Builds a generic Linear->ReLU->Dropout->... layer chain\n",
    "#\n",
    "# Inputs:\n",
    "#     hiddens: a list of all hidden sizes in order (not empty)\n",
    "#     input_features (default = 11): integer number of input features to give the model\n",
    "# Outputs:\n",
    "#     layers: the generic layers\n",
    "def build_generic_layers(hiddens, input_features=11):\n",
    "    full = [input_features] + hiddens + [11]\n",
    "    stop = len(full) - 1\n",
    "    layers = tuple()\n",
    "    for i in range(stop):\n",
    "        if i != (stop - 1):\n",
    "            layers += (\n",
    "                torch.nn.Linear(full[i], full[i+1], bias=True),\n",
    "                torch.nn.Dropout(0.25),\n",
    "                torch.nn.BatchNorm1d(full[i+1]),\n",
    "                torch.nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            layers += (\n",
    "                torch.nn.Linear(full[i], full[i+1], bias=False),\n",
    "            )\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa18b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests a generic n-layer network, given the number of hidden\n",
    "# layers and the potential sizes of every hidden layer\n",
    "#\n",
    "# Inputs:\n",
    "#     n: number of hidden layers (> 0)\n",
    "#     hidden_sizes: tuple of lists of hidden sizes (one list per layer)\n",
    "#       ex: ([1,2,3], [5,6,7]) would be two layers with three sizes each\n",
    "#     silent (default = True): Determines whether debug printouts will run\n",
    "#     input_features (default = 11): Number of input features to give the generic model\n",
    "# Outputs: None\n",
    "def test_generic_n_layer(n, hidden_sizes, silent=True, input_features=11):\n",
    "    assert n > 0\n",
    "    assert len(hidden_sizes) == n\n",
    "    \n",
    "    # Use cartesian product to cleverly hide recursive loops\n",
    "    # built with a generator too, so it doesn't eat RAM\n",
    "    accuracies = []\n",
    "    cool_product = itertools.product(*hidden_sizes)\n",
    "    for pattern in cool_product:\n",
    "        layers = build_generic_layers(list(pattern), input_features)\n",
    "        try:\n",
    "            accs = test_tuning(layers)\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"test_generic_n_layer: Training ended early due to Keyboard Interrupt. Raising an exception.\")\n",
    "            raise e\n",
    "        if not silent:\n",
    "            print(\"Tested with hidden sizes\", pattern)\n",
    "            print(get_accuracies_string(accs))\n",
    "            print()\n",
    "        accuracies.append(accs)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1a587e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(52.46153846153846, 93.92307692307692),\n",
       "  (55.10204081632652, 96.12244897959184),\n",
       "  (58.4375, 96.25)],\n",
       " [(53.92307692307692, 93.15384615384616),\n",
       "  (54.285714285714285, 95.61224489795919),\n",
       "  (55.625, 95.0)],\n",
       " [(52.53846153846153, 93.76923076923077),\n",
       "  (54.18367346938775, 95.81632653061224),\n",
       "  (53.43750000000001, 96.25)],\n",
       " [(48.38461538461539, 90.07692307692308),\n",
       "  (55.714285714285715, 95.81632653061224),\n",
       "  (56.25, 95.9375)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's how you can use all that code!\n",
    "# This line tests a single hidden layer with the following possible dims:\n",
    "#   11 -> 5  -> 11\n",
    "#   11 -> 10 -> 11\n",
    "#   11 -> 15 -> 11\n",
    "test_generic_n_layer(1, ([5, 10, 15],))\n",
    "\n",
    "# This line will test 2 hidden layers with the following combinations:\n",
    "#   11 -> 15 -> 5  -> 11\n",
    "#   11 -> 15 -> 10 -> 11\n",
    "#   11 -> 20 -> 5  -> 11\n",
    "#   11 -> 20 -> 10 -> 11\n",
    "test_generic_n_layer(2, ([15, 20], [5, 10],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83731f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise test:\n",
      "Test 1: [(63.87,94.56),(73.23,95.99),(66.15,94.58)\n",
      "Test 2: [(63.31,94.92),(71.19,95.34),(70.83,96.77)\n",
      "Test 3: [(63.74,94.33),(74.08,96.26),(70.21,95.62)\n",
      "Test 4: [(63.28,94.21),(74.18,96.09),(69.06,95.10)\n",
      "Test 5: [(64.87,94.79),(73.64,95.37),(72.29,96.04)\n"
     ]
    }
   ],
   "source": [
    "print(\"Noise test:\")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    1000\n",
    ")\n",
    "print(f\"Test 1: {get_accuracies_string(accs)}\")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    1000\n",
    ")\n",
    "print(f\"Test 2: {get_accuracies_string(accs)}\")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    1000\n",
    ")\n",
    "print(f\"Test 3: {get_accuracies_string(accs)}\")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    1000\n",
    ")\n",
    "print(f\"Test 4: {get_accuracies_string(accs)}\")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    1000\n",
    ")\n",
    "print(f\"Test 5: {get_accuracies_string(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b173f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(55.79,92.69),(62.96,93.88),(61.88,93.65)\n"
     ]
    }
   ],
   "source": [
    "accs = test_tuning(\n",
    "    build_generic_layers([85,95]),\n",
    "    1000\n",
    ")\n",
    "print(get_accuracies_string(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    2000\n",
    ")\n",
    "accs = test_tuning(\n",
    "    build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]),\n",
    "    2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4576cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to surround a string with quotes\n",
    "#\n",
    "# Inputs:\n",
    "#     tuple_string: a string you want to surround with quotes\n",
    "# Outputs:\n",
    "#     result: tuple string with quotes on either side, e.g. \"\\\"test\\\"\"\n",
    "def reformat_tuple_string(tuple_string):\n",
    "    assert isinstance(tuple_string, str)\n",
    "    result = \"\\\"\" + tuple_string + \"\\\"\"\n",
    "    return result\n",
    "\n",
    "#\"(5, 10, 15)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ca26c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a given array to a csv file\n",
    "# Inputs:\n",
    "#     name: string File name (not including extension)\n",
    "#     data: 2_D array_like that is ready to be saved as-is \n",
    "#     delimiter: character or string used to separate data's elements\n",
    "# Outputs:\n",
    "#     Saves a file \"{name}.csv\"\n",
    "def save_as_csv(name, data, delimiter):\n",
    "    \n",
    "    assert isinstance(name, str)\n",
    "    assert isinstance(delimiter, str)\n",
    "    data = np.array(data)\n",
    "    np.savetxt(f\"{name}.csv\", data, delimiter=str(delimiter), fmt=\"%s\")\n",
    "    \n",
    "#save_as_csv(\"test_formatting\", [reformat_tuple_string(\"(5, 10, 15)\")], \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42c94f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#     accuracies: list of lists of tuples. \n",
    "#         Each index i contains 2 measure of accuracy for 3 models in the form [(acc1, acc2), ..., (acc1, acc2)]\n",
    "#     hidden_sizes: tuple of lists of hidden sizes \n",
    "#     range_flag (default = True): \n",
    "#         Indicator of whether the data includes multiple models of different numbers of layers or just combinations\n",
    "#         of hidden state sizes for a model of one specific number of layers. \n",
    "# Outputs:\n",
    "#     accuracies_formatted:\n",
    "#         2-D array where each row represents the results for a particular combination of hidden sizes\n",
    "#         There should be 6 columns, the first 3 of which represent exact accuracy and the latter 3 of which represent\n",
    "#         accuracy with a tolerance of 1 rating point (i.e. adjacent classification in the quality scale).  \n",
    "def format_accuracies(accuracies, hidden_sizes, range_flag=False):\n",
    "    print(f\"format_accuracies: len(accuracies) = {len(accuracies)}, len(hidden_sizes) = {len(hidden_sizes)}\")\n",
    "    print(f\"format_accuracies: accuracies = {accuracies}\")\n",
    "\n",
    "    accuracies_formatted = []        \n",
    "    accuracies_temp = []\n",
    "    \n",
    "    #Determines if the loop runs once or once per hidden_sizes combination per model in [1, n]\n",
    "    range_flag_switch = len(hidden_sizes) \n",
    "    if not range_flag:\n",
    "        range_flag_switch = 1\n",
    "    print(f\"format_accuracies: range_flag_switch = {range_flag_switch}\")\n",
    "    \n",
    "   \n",
    "    for n in range(range_flag_switch):\n",
    "        hidden_sizes_cur = hidden_sizes[:n+1] if range_flag else hidden_sizes\n",
    "        cartesian_product = itertools.product(*hidden_sizes_cur)\n",
    "        idx = 0\n",
    "        for combination in cartesian_product:\n",
    "            accuracy_cur = None\n",
    "            if range_flag:\n",
    "                accuracy_cur = accuracies[n][idx]\n",
    "            else:\n",
    "                accuracy_cur = accuracies[idx]\n",
    "            print(f\"n = {n}, idx = {idx}, range_flag_switch = {range_flag_switch}, accuracy_cur = {accuracy_cur}\")\n",
    "            temp_row = []\n",
    "            temp_row.append(reformat_tuple_string(str(combination)))\n",
    "            for i in range(3):\n",
    "                # For each dataset in [Combined, White Red]\n",
    "                for j in range(2):\n",
    "                    # For each accuracy in (exact, t1)\n",
    "                    temp_row.append(str(accuracy_cur[i][j]))\n",
    "            accuracies_temp.append(temp_row)\n",
    "            idx += 1\n",
    "    accuracies_formatted = accuracies_temp\n",
    "    \n",
    "    print(f\"format_accuracies: accuracies_formatted(len = {len(accuracies_formatted)}) = {accuracies_formatted}\")\n",
    "    total_accuracies = 0\n",
    "    if range_flag:\n",
    "        for i in range(len(accuracies)):\n",
    "            total_accuracies += len(accuracies[i])\n",
    "    else:\n",
    "        total_accuracies += len(accuracies)\n",
    "    assert len(accuracies_formatted) == total_accuracies\n",
    "    \n",
    "    return accuracies_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8fe6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the hidden_sizes tuple used by the generic network\n",
    "#     testing methods\n",
    "# Inputs:\n",
    "#     n: Number of layers to generate hidden_sizes for\n",
    "#     starts_and_ends: length n list of integer tuples of the form [(start, end), ..., (start, end)]\n",
    "#     step_sizes: length n list of integer step sizes for each \n",
    "#         number of layers, [1, n]\n",
    "# Outputs:\n",
    "#     hidden_sizes: tuple of lists of hidden sizes\n",
    "def generate_hidden_sizes(n, starts_and_ends, step_sizes):\n",
    "    assert n > 0\n",
    "    assert len(starts_and_ends) == n\n",
    "    assert len(step_sizes) == n\n",
    "    assert isinstance(starts_and_ends, list)\n",
    "    assert isinstance(step_sizes, list)\n",
    "    hidden_sizes = None\n",
    "    for i in range(n):\n",
    "        start, end = starts_and_ends[i]\n",
    "        step_size = step_sizes[i]\n",
    "        hidden_sizes_n = list(range(start, end+1, step_size))\n",
    "        if hidden_sizes is None:\n",
    "            hidden_sizes = (hidden_sizes_n, )\n",
    "        else:\n",
    "            hidden_sizes += (hidden_sizes_n, )\n",
    "    return hidden_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1083ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test_generic_n_layer for layer sizes [1, max_n], aggregate the results and save them to a .csv file\n",
    "# Inputs:\n",
    "#     max_n: maximum number of layers to test through starting at 1\n",
    "#     hidden_sizes: max_n length tuple of hidden size lists\n",
    "#     filename: string excluding file extension to name the saved data file\n",
    "#     delimiter: delimiter between elements in the csv file (since it is acceptable to Excel to use things that aren't commas)\n",
    "#     silent (default = True): Determines whether debug printouts will run\n",
    "#     input_features (default = 11): Number of input features to give the models being tested\n",
    "# Outputs:\n",
    "#     Saves the resulting data to a file\n",
    "def test_and_save(max_n, hidden_sizes, filename, delimiter, silent=True, input_features=11):\n",
    "    #accuracies_max_n = []\n",
    "    assert len(hidden_sizes) == max_n\n",
    "    for n in range(max_n):\n",
    "        hidden_sizes_cur = hidden_sizes[:n+1]\n",
    "        assert len(hidden_sizes_cur) == n+1\n",
    "        try:\n",
    "            accuracies = test_generic_n_layer(n+1, hidden_sizes_cur, silent, input_features)\n",
    "        except KeyboardInterrupt as e:\n",
    "            print(\"test_and_save: Training ended early due to Keyboard Interrupt. Raising an exception.\")\n",
    "            raise e\n",
    "        if not silent: print(f\"accuracies generated (but not yet formatted): {accuracies}\")\n",
    "        data = format_accuracies(accuracies, hidden_sizes_cur[:n+1], False)\n",
    "        save_as_csv(f\"{filename}-{str(n+1)}\", data, \";\")\n",
    "        #accuracies_max_n.append(accuracies)\n",
    "    \n",
    "    #print(f\"accuracies generated (but not yet formatted): {accuracies_max_n}\")#remove this\n",
    "    #data = format_accuracies(accuracies_max_n, hidden_sizes)\n",
    "    #save_as_csv(filename+str(n), data, delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4823d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_hidden_sizes simple test result = ([5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100],)\n",
      "Tested with hidden sizes (5,)\n",
      "[(55.05,95.36),(52.76,95.17),(59.48,96.04)\n",
      "\n",
      "Tested with hidden sizes (10,)\n",
      "[(55.62,95.26),(54.97,95.78),(60.42,96.77)\n",
      "\n",
      "Tested with hidden sizes (15,)\n",
      "[(55.77,95.54),(53.27,95.99),(58.96,96.35)\n",
      "\n",
      "Tested with hidden sizes (20,)\n",
      "[(53.56,94.74),(55.10,95.75),(60.52,97.29)\n",
      "\n",
      "Tested with hidden sizes (25,)\n",
      "[(54.49,94.95),(54.63,94.90),(58.85,97.50)\n",
      "\n",
      "Tested with hidden sizes (30,)\n",
      "[(55.23,95.03),(54.46,94.63),(59.58,96.67)\n",
      "\n",
      "Tested with hidden sizes (35,)\n",
      "[(55.41,95.28),(55.10,95.37),(58.54,96.67)\n",
      "\n",
      "Tested with hidden sizes (40,)\n",
      "[(53.90,95.49),(53.37,95.37),(58.12,95.94)\n",
      "\n",
      "Tested with hidden sizes (45,)\n",
      "[(55.05,94.72),(54.39,93.91),(62.60,96.46)\n",
      "\n",
      "Tested with hidden sizes (50,)\n",
      "[(54.49,95.31),(54.25,95.07),(58.75,96.67)\n",
      "\n",
      "Tested with hidden sizes (55,)\n",
      "[(54.79,94.62),(55.51,95.14),(57.81,96.46)\n",
      "\n",
      "Tested with hidden sizes (60,)\n",
      "[(55.69,95.56),(54.39,94.83),(56.15,94.27)\n",
      "\n",
      "Tested with hidden sizes (65,)\n",
      "[(54.38,95.21),(54.97,94.32),(61.88,96.56)\n",
      "\n",
      "Tested with hidden sizes (70,)\n",
      "[(53.18,94.54),(54.76,95.24),(57.81,96.67)\n",
      "\n",
      "Tested with hidden sizes (75,)\n",
      "[(54.62,94.74),(55.03,95.48),(58.85,96.25)\n",
      "\n",
      "Tested with hidden sizes (80,)\n",
      "[(56.31,95.64),(56.73,94.42),(60.73,96.98)\n",
      "\n",
      "Tested with hidden sizes (85,)\n",
      "[(54.97,94.79),(55.88,95.20),(60.62,95.21)\n",
      "\n",
      "Tested with hidden sizes (90,)\n",
      "[(53.77,94.56),(54.39,95.14),(62.40,96.35)\n",
      "\n",
      "Tested with hidden sizes (95,)\n",
      "[(54.13,94.41),(55.85,94.35),(60.73,96.35)\n",
      "\n",
      "Tested with hidden sizes (100,)\n",
      "[(55.21,95.10),(55.24,94.15),(59.48,96.35)\n",
      "\n",
      "accuracies generated (but not yet formatted): [[(55.051282051282044, 95.35897435897436), (52.755102040816325, 95.17006802721089), (59.479166666666664, 96.04166666666667)], [(55.61538461538462, 95.25641025641026), (54.965986394557824, 95.78231292517006), (60.416666666666664, 96.77083333333333)], [(55.769230769230774, 95.53846153846153), (53.26530612244898, 95.98639455782313), (58.958333333333336, 96.35416666666667)], [(53.56410256410257, 94.74358974358974), (55.10204081632653, 95.74829931972789), (60.520833333333336, 97.29166666666667)], [(54.48717948717948, 94.94871794871796), (54.625850340136054, 94.89795918367345), (58.854166666666664, 97.5)], [(55.230769230769226, 95.02564102564104), (54.45578231292517, 94.62585034013607), (59.583333333333336, 96.66666666666667)], [(55.41025641025641, 95.28205128205127), (55.10204081632653, 95.37414965986393), (58.541666666666664, 96.66666666666667)], [(53.89743589743589, 95.48717948717949), (53.367346938775505, 95.37414965986393), (58.125, 95.9375)], [(55.051282051282044, 94.71794871794873), (54.38775510204082, 93.91156462585035), (62.604166666666664, 96.45833333333333)], [(54.48717948717948, 95.3076923076923), (54.25170068027211, 95.06802721088435), (58.75, 96.66666666666667)], [(54.794871794871796, 94.6153846153846), (55.51020408163265, 95.13605442176869), (57.8125, 96.45833333333333)], [(55.6923076923077, 95.56410256410258), (54.38775510204082, 94.82993197278911), (56.145833333333336, 94.27083333333333)], [(54.38461538461539, 95.20512820512822), (54.96598639455783, 94.31972789115646), (61.875, 96.5625)], [(53.17948717948718, 94.53846153846153), (54.76190476190476, 95.23809523809524), (57.8125, 96.66666666666667)], [(54.61538461538461, 94.74358974358974), (55.034013605442176, 95.47619047619048), (58.854166666666664, 96.25)], [(56.3076923076923, 95.64102564102564), (56.734693877551024, 94.421768707483), (60.729166666666664, 96.97916666666667)], [(54.97435897435898, 94.79487179487178), (55.8843537414966, 95.20408163265306), (60.625, 95.20833333333333)], [(53.769230769230774, 94.56410256410255), (54.38775510204081, 95.13605442176872), (62.395833333333336, 96.35416666666667)], [(54.12820512820513, 94.41025641025641), (55.85034013605442, 94.35374149659863), (60.729166666666664, 96.35416666666667)], [(55.205128205128204, 95.10256410256409), (55.23809523809524, 94.14965986394559), (59.479166666666664, 96.35416666666667)]]\n",
      "format_accuracies: len(accuracies) = 20, len(hidden_sizes) = 1\n",
      "format_accuracies: accuracies = [[(55.051282051282044, 95.35897435897436), (52.755102040816325, 95.17006802721089), (59.479166666666664, 96.04166666666667)], [(55.61538461538462, 95.25641025641026), (54.965986394557824, 95.78231292517006), (60.416666666666664, 96.77083333333333)], [(55.769230769230774, 95.53846153846153), (53.26530612244898, 95.98639455782313), (58.958333333333336, 96.35416666666667)], [(53.56410256410257, 94.74358974358974), (55.10204081632653, 95.74829931972789), (60.520833333333336, 97.29166666666667)], [(54.48717948717948, 94.94871794871796), (54.625850340136054, 94.89795918367345), (58.854166666666664, 97.5)], [(55.230769230769226, 95.02564102564104), (54.45578231292517, 94.62585034013607), (59.583333333333336, 96.66666666666667)], [(55.41025641025641, 95.28205128205127), (55.10204081632653, 95.37414965986393), (58.541666666666664, 96.66666666666667)], [(53.89743589743589, 95.48717948717949), (53.367346938775505, 95.37414965986393), (58.125, 95.9375)], [(55.051282051282044, 94.71794871794873), (54.38775510204082, 93.91156462585035), (62.604166666666664, 96.45833333333333)], [(54.48717948717948, 95.3076923076923), (54.25170068027211, 95.06802721088435), (58.75, 96.66666666666667)], [(54.794871794871796, 94.6153846153846), (55.51020408163265, 95.13605442176869), (57.8125, 96.45833333333333)], [(55.6923076923077, 95.56410256410258), (54.38775510204082, 94.82993197278911), (56.145833333333336, 94.27083333333333)], [(54.38461538461539, 95.20512820512822), (54.96598639455783, 94.31972789115646), (61.875, 96.5625)], [(53.17948717948718, 94.53846153846153), (54.76190476190476, 95.23809523809524), (57.8125, 96.66666666666667)], [(54.61538461538461, 94.74358974358974), (55.034013605442176, 95.47619047619048), (58.854166666666664, 96.25)], [(56.3076923076923, 95.64102564102564), (56.734693877551024, 94.421768707483), (60.729166666666664, 96.97916666666667)], [(54.97435897435898, 94.79487179487178), (55.8843537414966, 95.20408163265306), (60.625, 95.20833333333333)], [(53.769230769230774, 94.56410256410255), (54.38775510204081, 95.13605442176872), (62.395833333333336, 96.35416666666667)], [(54.12820512820513, 94.41025641025641), (55.85034013605442, 94.35374149659863), (60.729166666666664, 96.35416666666667)], [(55.205128205128204, 95.10256410256409), (55.23809523809524, 94.14965986394559), (59.479166666666664, 96.35416666666667)]]\n",
      "format_accuracies: range_flag_switch = 1\n",
      "n = 0, idx = 0, range_flag_switch = 1, accuracy_cur = [(55.051282051282044, 95.35897435897436), (52.755102040816325, 95.17006802721089), (59.479166666666664, 96.04166666666667)]\n",
      "n = 0, idx = 1, range_flag_switch = 1, accuracy_cur = [(55.61538461538462, 95.25641025641026), (54.965986394557824, 95.78231292517006), (60.416666666666664, 96.77083333333333)]\n",
      "n = 0, idx = 2, range_flag_switch = 1, accuracy_cur = [(55.769230769230774, 95.53846153846153), (53.26530612244898, 95.98639455782313), (58.958333333333336, 96.35416666666667)]\n",
      "n = 0, idx = 3, range_flag_switch = 1, accuracy_cur = [(53.56410256410257, 94.74358974358974), (55.10204081632653, 95.74829931972789), (60.520833333333336, 97.29166666666667)]\n",
      "n = 0, idx = 4, range_flag_switch = 1, accuracy_cur = [(54.48717948717948, 94.94871794871796), (54.625850340136054, 94.89795918367345), (58.854166666666664, 97.5)]\n",
      "n = 0, idx = 5, range_flag_switch = 1, accuracy_cur = [(55.230769230769226, 95.02564102564104), (54.45578231292517, 94.62585034013607), (59.583333333333336, 96.66666666666667)]\n",
      "n = 0, idx = 6, range_flag_switch = 1, accuracy_cur = [(55.41025641025641, 95.28205128205127), (55.10204081632653, 95.37414965986393), (58.541666666666664, 96.66666666666667)]\n",
      "n = 0, idx = 7, range_flag_switch = 1, accuracy_cur = [(53.89743589743589, 95.48717948717949), (53.367346938775505, 95.37414965986393), (58.125, 95.9375)]\n",
      "n = 0, idx = 8, range_flag_switch = 1, accuracy_cur = [(55.051282051282044, 94.71794871794873), (54.38775510204082, 93.91156462585035), (62.604166666666664, 96.45833333333333)]\n",
      "n = 0, idx = 9, range_flag_switch = 1, accuracy_cur = [(54.48717948717948, 95.3076923076923), (54.25170068027211, 95.06802721088435), (58.75, 96.66666666666667)]\n",
      "n = 0, idx = 10, range_flag_switch = 1, accuracy_cur = [(54.794871794871796, 94.6153846153846), (55.51020408163265, 95.13605442176869), (57.8125, 96.45833333333333)]\n",
      "n = 0, idx = 11, range_flag_switch = 1, accuracy_cur = [(55.6923076923077, 95.56410256410258), (54.38775510204082, 94.82993197278911), (56.145833333333336, 94.27083333333333)]\n",
      "n = 0, idx = 12, range_flag_switch = 1, accuracy_cur = [(54.38461538461539, 95.20512820512822), (54.96598639455783, 94.31972789115646), (61.875, 96.5625)]\n",
      "n = 0, idx = 13, range_flag_switch = 1, accuracy_cur = [(53.17948717948718, 94.53846153846153), (54.76190476190476, 95.23809523809524), (57.8125, 96.66666666666667)]\n",
      "n = 0, idx = 14, range_flag_switch = 1, accuracy_cur = [(54.61538461538461, 94.74358974358974), (55.034013605442176, 95.47619047619048), (58.854166666666664, 96.25)]\n",
      "n = 0, idx = 15, range_flag_switch = 1, accuracy_cur = [(56.3076923076923, 95.64102564102564), (56.734693877551024, 94.421768707483), (60.729166666666664, 96.97916666666667)]\n",
      "n = 0, idx = 16, range_flag_switch = 1, accuracy_cur = [(54.97435897435898, 94.79487179487178), (55.8843537414966, 95.20408163265306), (60.625, 95.20833333333333)]\n",
      "n = 0, idx = 17, range_flag_switch = 1, accuracy_cur = [(53.769230769230774, 94.56410256410255), (54.38775510204081, 95.13605442176872), (62.395833333333336, 96.35416666666667)]\n",
      "n = 0, idx = 18, range_flag_switch = 1, accuracy_cur = [(54.12820512820513, 94.41025641025641), (55.85034013605442, 94.35374149659863), (60.729166666666664, 96.35416666666667)]\n",
      "n = 0, idx = 19, range_flag_switch = 1, accuracy_cur = [(55.205128205128204, 95.10256410256409), (55.23809523809524, 94.14965986394559), (59.479166666666664, 96.35416666666667)]\n",
      "format_accuracies: accuracies_formatted(len = 20) = [['\"(5,)\"', '55.051282051282044', '95.35897435897436', '52.755102040816325', '95.17006802721089', '59.479166666666664', '96.04166666666667'], ['\"(10,)\"', '55.61538461538462', '95.25641025641026', '54.965986394557824', '95.78231292517006', '60.416666666666664', '96.77083333333333'], ['\"(15,)\"', '55.769230769230774', '95.53846153846153', '53.26530612244898', '95.98639455782313', '58.958333333333336', '96.35416666666667'], ['\"(20,)\"', '53.56410256410257', '94.74358974358974', '55.10204081632653', '95.74829931972789', '60.520833333333336', '97.29166666666667'], ['\"(25,)\"', '54.48717948717948', '94.94871794871796', '54.625850340136054', '94.89795918367345', '58.854166666666664', '97.5'], ['\"(30,)\"', '55.230769230769226', '95.02564102564104', '54.45578231292517', '94.62585034013607', '59.583333333333336', '96.66666666666667'], ['\"(35,)\"', '55.41025641025641', '95.28205128205127', '55.10204081632653', '95.37414965986393', '58.541666666666664', '96.66666666666667'], ['\"(40,)\"', '53.89743589743589', '95.48717948717949', '53.367346938775505', '95.37414965986393', '58.125', '95.9375'], ['\"(45,)\"', '55.051282051282044', '94.71794871794873', '54.38775510204082', '93.91156462585035', '62.604166666666664', '96.45833333333333'], ['\"(50,)\"', '54.48717948717948', '95.3076923076923', '54.25170068027211', '95.06802721088435', '58.75', '96.66666666666667'], ['\"(55,)\"', '54.794871794871796', '94.6153846153846', '55.51020408163265', '95.13605442176869', '57.8125', '96.45833333333333'], ['\"(60,)\"', '55.6923076923077', '95.56410256410258', '54.38775510204082', '94.82993197278911', '56.145833333333336', '94.27083333333333'], ['\"(65,)\"', '54.38461538461539', '95.20512820512822', '54.96598639455783', '94.31972789115646', '61.875', '96.5625'], ['\"(70,)\"', '53.17948717948718', '94.53846153846153', '54.76190476190476', '95.23809523809524', '57.8125', '96.66666666666667'], ['\"(75,)\"', '54.61538461538461', '94.74358974358974', '55.034013605442176', '95.47619047619048', '58.854166666666664', '96.25'], ['\"(80,)\"', '56.3076923076923', '95.64102564102564', '56.734693877551024', '94.421768707483', '60.729166666666664', '96.97916666666667'], ['\"(85,)\"', '54.97435897435898', '94.79487179487178', '55.8843537414966', '95.20408163265306', '60.625', '95.20833333333333'], ['\"(90,)\"', '53.769230769230774', '94.56410256410255', '54.38775510204081', '95.13605442176872', '62.395833333333336', '96.35416666666667'], ['\"(95,)\"', '54.12820512820513', '94.41025641025641', '55.85034013605442', '94.35374149659863', '60.729166666666664', '96.35416666666667'], ['\"(100,)\"', '55.205128205128204', '95.10256410256409', '55.23809523809524', '94.14965986394559', '59.479166666666664', '96.35416666666667']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"generate_hidden_sizes simple test result = {generate_hidden_sizes(1, [(5, 100)], [5])}\")   \n",
    "\n",
    "\n",
    "try:\n",
    "    #test_and_save(1, generate_hidden_sizes(1, [(5, 100)], [5]), \"big_test_n1\", \";\", False)\n",
    "    #test_and_save(3, generate_hidden_sizes(3, [(5, 100), (5, 100), (5, 100)], [5, 5, 5]), \"Big_Test_n_equals_3_h_spans_5_to_100\", \";\", False)\n",
    "    #test_and_save(2, generate_hidden_sizes(2, [(5, 10), (5, 10)], [5, 5]), \"medium_test\", \";\", False)\n",
    "    \n",
    "    #test_and_save(1, generate_hidden_sizes(1, [(5, 100)], [5]), \"big_test_n1\", \";\", False)\n",
    "    test_and_save(2, generate_hidden_sizes(2, [(5, 100), (5, 100)], [5, 5]), \"big_test_n2\", \";\", False)\n",
    "    test_and_save(3, generate_hidden_sizes(3, [(5, 100), (5, 100), (5, 100)], [5, 5, 5]), \"big_test_n3\", \";\", False)\n",
    "    \n",
    "    #test_and_save(3, generate_hidden_sizes(3, [(5, 15), (5, 15), (5, 15)], [5, 5, 5]), \"test2_nequals3_hsizerange5to15\", \";\", False)\n",
    "except KeyboardInterrupt as e:\n",
    "    print(\"Received a KeyboardInterrupt. Try testing again when you're ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096fe95",
   "metadata": {},
   "source": [
    "## Training an Optimal Model\n",
    "   \n",
    "Now that we have found an optimal configuration for our model, we're going to store trained models to be used for our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e8f94b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering training loop\n",
      "Trained model 0\n",
      "Trained model 1\n",
      "Trained model 2\n"
     ]
    }
   ],
   "source": [
    "optimal_model = WineQualityModel(build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]))\n",
    "optimal_model_white = WineQualityModel(build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]))\n",
    "optimal_model_red = WineQualityModel(build_generic_layers([85, 95, 105, 115, 115, 105, 95, 45]))\n",
    "\n",
    "optimal_models = [optimal_model, optimal_model_white, optimal_model_red]\n",
    "\n",
    "loaders = get_random_loaders(data_array, data_array_white, data_array_red)\n",
    "print(\"Entering training loop\")\n",
    "for i in range(3):\n",
    "    cur_loaders = loaders[i]\n",
    "    cur_model = optimal_models[i]\n",
    "    cur_optim = torch.optim.Adam(cur_model.parameters(), lr=1e-3)\n",
    "    cur_criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_network(cur_model, cur_loaders[0], cur_loaders[1], cur_criterion, cur_optim, 1000)\n",
    "    cur_model.eval()\n",
    "    print(f\"Trained model {i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035aea4",
   "metadata": {},
   "source": [
    "## Computational Experiment #1:\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "For our first computational experiment we want to try and isolate the data's most important feature. To accomplish that, we're going to try two different methods:\n",
    "- Retraining models that take 10 input features on every length-10 subset of the 11 data features\n",
    "- Using our optimal trained model from hypertuning and zeroing out one feature per trial.\n",
    "\n",
    "Hypothesis: There is a most important feature in the data for classifying the quality of a wine, and all the features are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ac46cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection on a new model for each 10-length subset of the input features\n",
    "# Inputs:\n",
    "#     hidden_sizes: List of hidden sizes in order to build a model with.\n",
    "#     silent (default = True): Determines whether debug printouts will run.\n",
    "#     input_features (default = 10): Number of input features for each retrained model to use\n",
    "# Outputs:\n",
    "#     Prints a list of accuracies for all 11 feature selection experiments\n",
    "def feature_select_retrain(hidden_sizes, silent=True, input_features=10):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    accuracy = []\n",
    "    # We have: data_array, data_array_white, data_array_red as well\n",
    "    for i in range(11):\n",
    "        # Remove one column of the data arrays to test how the model does without it\n",
    "        cur_data_array = np.delete(np.copy(data_array), i, 1)\n",
    "        cur_data_array_white = np.delete(np.copy(data_array_white), i, 1)\n",
    "        cur_data_array_red = np.delete(np.copy(data_array_red), i, 1)\n",
    "        \n",
    "        # Get loaders for new data without feature (column) i\n",
    "        loaders = get_random_loaders(cur_data_array, cur_data_array_white, cur_data_array_red)\n",
    "        true_lists = []\n",
    "        pred_lists = []\n",
    "        for j in range(3):\n",
    "            # For each dataset in [Combined, White, Red]:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "            cur_loaders = loaders[j]\n",
    "            cur_layers = build_generic_layers(hidden_sizes, input_features)\n",
    "            cur_model = WineQualityModel(cur_layers) # cur_model is the new model we're training on altered data\n",
    "            cur_optimizer = torch.optim.Adam(cur_model.parameters(), lr=1e-3)\n",
    "            try:\n",
    "                # train and test new model on altered data\n",
    "                acc, true, pred = train_and_test(cur_model, *cur_loaders, criterion, \\\n",
    "                                         cur_optimizer, nepoch=250, mode=f\"Model ({i}, {j})\", silent=silent)\n",
    "            except KeyboardInterrupt as e:\n",
    "                # Allow for keyboard interrupts during training\n",
    "                print(\"feature_select_retrain Training ended early. Exiting\")\n",
    "                return\n",
    "            true_lists.append(true)\n",
    "            pred_lists.append(pred)\n",
    "            \n",
    "        accs = []\n",
    "        for j in range(3):\n",
    "            # For each dataset in [Combined, White, Red]:\n",
    "            cur_exact_acc, cur_t1 = compute_model_accuracies(true_lists[j], pred_lists[j]) # Compute accuracies from true/pred lists\n",
    "            tuple_acc = (cur_exact_acc, cur_t1) # Tuple pack accuracies for the to_string method\n",
    "            accs.append(tuple_acc)\n",
    "        acc_str = get_accuracies_string(accs)\n",
    "        accuracy.append(accs) # Append this trial's accuracies to the master list\n",
    "        print(f\"feature_select_retrain Trial {i}: Feature at index {i} not being considered. Accuracies = {acc_str}\")\n",
    "    \n",
    "    # Loop through each trial\n",
    "    worst_exacts = [-1, -1, -1]\n",
    "    worst_t1s = [-1, -1, -1]\n",
    "    best_exacts = [-1, -1, -1]\n",
    "    best_t1s = [-1, -1, -1]\n",
    "    \n",
    "    idx = 0\n",
    "    for trial in accuracy:\n",
    "        # For each trial of the 11 on new models with altered data\n",
    "        for i in range(3):\n",
    "            # For each dataset in [Combined, White, Red]\n",
    "            cur_tuple = trial[i]\n",
    "            if worst_exacts[i] == -1 or cur_tuple[0] < accuracy[worst_exacts[i]][i][0]:\n",
    "                worst_exacts[i] = idx\n",
    "            if worst_t1s[i] == -1 or cur_tuple[0] < accuracy[worst_t1s[i]][i][0]:\n",
    "                worst_t1s[i] = idx\n",
    "            if best_exacts[i] == -1 or cur_tuple[0] > accuracy[best_exacts[i]][i][0]:\n",
    "                best_exacts[i] = idx\n",
    "            if best_t1s[i] == -1 or cur_tuple[0] > accuracy[best_t1s[i]][i][0]:\n",
    "                best_t1s[i] = idx\n",
    "        idx += 1\n",
    "    \n",
    "    print(f\"Worst Trial for Combined Data Set Exact Accuracy = {worst_exacts[0]}\")\n",
    "    print(f\"Worst Trial for White Wine Data Set Exact Accuracy = {worst_exacts[1]}\")\n",
    "    print(f\"Worst Trial for Red Wine Data Set Exact Accuracy = {worst_exacts[2]}\")\n",
    "    print(f\"Worst Trial for Combined Data Set T1 Accuracy = {worst_t1s[0]}\")\n",
    "    print(f\"Worst Trial for White Wine Data Set T1 Accuracy = {worst_t1s[1]}\")\n",
    "    print(f\"Worst Trial for Red Wine Data Set T1 Accuracy = {worst_t1s[2]}\")\n",
    "    print(f\"Best Trial for Combined Data Set Exact Accuracy = {best_exacts[0]}\")\n",
    "    print(f\"Best Trial for White Wine Data Set Exact Accuracy = {best_exacts[1]}\")\n",
    "    print(f\"Best Trial for Red Wine Data Set Exact Accuracy = {best_exacts[2]}\")\n",
    "    print(f\"Best Trial for Combined Data Set T1 Accuracy = {best_t1s[0]}\")\n",
    "    print(f\"Best Trial for White Wine Data Set T1 Accuracy = {best_t1s[1]}\")\n",
    "    print(f\"Best Trial for Red Wine Data Set T1 Accuracy = {best_t1s[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3041b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_retrain Trial 0: Feature at index 0 not being considered. Accuracies = [(51.38,91.46),(49.90,91.63),(57.50,97.19)\n",
      "feature_select_retrain Trial 1: Feature at index 1 not being considered. Accuracies = [(43.31,87.62),(44.80,90.61),(58.75,96.25)\n",
      "feature_select_retrain Trial 2: Feature at index 2 not being considered. Accuracies = [(53.92,93.77),(50.20,92.35),(55.94,95.94)\n",
      "feature_select_retrain Trial 3: Feature at index 3 not being considered. Accuracies = [(51.38,94.69),(50.10,92.96),(59.38,95.62)\n",
      "feature_select_retrain Trial 4: Feature at index 4 not being considered. Accuracies = [(53.46,93.85),(46.63,92.24),(57.19,96.88)\n",
      "feature_select_retrain Trial 5: Feature at index 5 not being considered. Accuracies = [(53.08,94.23),(48.98,92.45),(56.56,95.62)\n",
      "feature_select_retrain Trial 6: Feature at index 6 not being considered. Accuracies = [(53.85,95.31),(50.41,94.08),(61.56,96.88)\n",
      "feature_select_retrain Trial 7: Feature at index 7 not being considered. Accuracies = [(49.62,91.38),(46.84,92.96),(62.50,96.25)\n",
      "feature_select_retrain Trial 8: Feature at index 8 not being considered. Accuracies = [(52.85,95.15),(49.29,93.57),(59.38,95.94)\n",
      "feature_select_retrain Trial 9: Feature at index 9 not being considered. Accuracies = [(49.38,92.77),(46.02,89.39),(56.56,96.25)\n",
      "feature_select_retrain Trial 10: Feature at index 10 not being considered. Accuracies = [(50.23,94.62),(48.37,93.88),(54.37,95.00)\n",
      "Worst Trial for Combined Data Set Exact Accuracy = 1\n",
      "Worst Trial for White Wine Data Set Exact Accuracy = 1\n",
      "Worst Trial for Red Wine Data Set Exact Accuracy = 10\n",
      "Worst Trial for Combined Data Set T1 Accuracy = 1\n",
      "Worst Trial for White Wine Data Set T1 Accuracy = 1\n",
      "Worst Trial for Red Wine Data Set T1 Accuracy = 10\n",
      "Best Trial for Combined Data Set Exact Accuracy = 2\n",
      "Best Trial for White Wine Data Set Exact Accuracy = 6\n",
      "Best Trial for Red Wine Data Set Exact Accuracy = 7\n",
      "Best Trial for Combined Data Set T1 Accuracy = 2\n",
      "Best Trial for White Wine Data Set T1 Accuracy = 6\n",
      "Best Trial for Red Wine Data Set T1 Accuracy = 7\n"
     ]
    }
   ],
   "source": [
    "feature_select_retrain([85, 95, 105, 115, 115, 105, 95, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c0d1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_dropout(optimal_models):\n",
    "    accuracy = []\n",
    "    for i in range(11):\n",
    "        # Zero out the ith column in each data_array for datasets [Combined, White, Red]\n",
    "        cur_data_array = np.copy(data_array)\n",
    "        cur_data_array_white = np.copy(data_array_white)\n",
    "        cur_data_array_red = np.copy(data_array_red)\n",
    "        cur_data_array[:, i] = 0\n",
    "        cur_data_array_white[:, i] = 0\n",
    "        cur_data_array_red[:, i] = 0\n",
    "        \n",
    "        # Get loaders for new data with feature (column) i set to zeroes\n",
    "        loaders = get_random_loaders(cur_data_array, cur_data_array_white, cur_data_array_red)\n",
    "        true_lists = []\n",
    "        pred_lists = []\n",
    "        for j in range(3):\n",
    "            # For each dataset in [Combined, White, Red]\n",
    "         \n",
    "            cur_loaders = loaders[j]\n",
    "            # Test pre-trained optimal model\n",
    "            acc, true, pred = test_network(optimal_models[j], cur_loaders[2])\n",
    "            \n",
    "            true_lists.append(true)\n",
    "            pred_lists.append(pred)\n",
    "            \n",
    "        accs = []\n",
    "        for j in range(3):\n",
    "            # For each dataset in [Combined, White, Red], compute accuracies and format them for the to_string\n",
    "            cur_exact_acc, cur_t1 = compute_model_accuracies(true_lists[j], pred_lists[j])\n",
    "            tuple_acc = (cur_exact_acc, cur_t1)\n",
    "            accs.append(tuple_acc)\n",
    "        acc_str = get_accuracies_string(accs)\n",
    "        accuracy.append(accs) # Add all three models' accuracies to the master list\n",
    "        print(f\"feature_select_dropout Trial {i}: Feature at index {i} not being considered. Accuracies = {acc_str}\")\n",
    "    \n",
    "    # Loop through each trial\n",
    "    worst_exacts = [-1, -1, -1]\n",
    "    worst_t1s = [-1, -1, -1]\n",
    "    best_exacts = [-1, -1, -1]\n",
    "    best_t1s = [-1, -1, -1]\n",
    "    \n",
    "    idx = 0\n",
    "    for trial in accuracy: \n",
    "        # For each of the 11 trials in which a column is zeroed:\n",
    "        for i in range(3):\n",
    "            # For each dataset in [Combined, White, Red]\n",
    "            cur_tuple = trial[i]\n",
    "            if worst_exacts[i] == -1 or cur_tuple[0] < accuracy[worst_exacts[i]][i][0]:\n",
    "                worst_exacts[i] = idx\n",
    "            if worst_t1s[i] == -1 or cur_tuple[0] < accuracy[worst_t1s[i]][i][0]:\n",
    "                worst_t1s[i] = idx\n",
    "            if best_exacts[i] == -1 or cur_tuple[0] > accuracy[best_exacts[i]][i][0]:\n",
    "                best_exacts[i] = idx\n",
    "            if best_t1s[i] == -1 or cur_tuple[0] > accuracy[best_t1s[i]][i][0]:\n",
    "                best_t1s[i] = idx\n",
    "        idx += 1\n",
    "    \n",
    "    print(f\"Worst Trial for Combined Data Set Exact Accuracy = {worst_exacts[0]}\")\n",
    "    print(f\"Worst Trial for White Wine Data Set Exact Accuracy = {worst_exacts[1]}\")\n",
    "    print(f\"Worst Trial for Red Wine Data Set Exact Accuracy = {worst_exacts[2]}\")\n",
    "    print(f\"Worst Trial for Combined Data Set T1 Accuracy = {worst_t1s[0]}\")\n",
    "    print(f\"Worst Trial for White Wine Data Set T1 Accuracy = {worst_t1s[1]}\")\n",
    "    print(f\"Worst Trial for Red Wine Data Set T1 Accuracy = {worst_t1s[2]}\")\n",
    "    print(f\"Best Trial for Combined Data Set Exact Accuracy = {best_exacts[0]}\")\n",
    "    print(f\"Best Trial for White Wine Data Set Exact Accuracy = {best_exacts[1]}\")\n",
    "    print(f\"Best Trial for Red Wine Data Set Exact Accuracy = {best_exacts[2]}\")\n",
    "    print(f\"Best Trial for Combined Data Set T1 Accuracy = {best_t1s[0]}\")\n",
    "    print(f\"Best Trial for White Wine Data Set T1 Accuracy = {best_t1s[1]}\")\n",
    "    print(f\"Best Trial for Red Wine Data Set T1 Accuracy = {best_t1s[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f74f711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_select_dropout Trial 0: Feature at index 0 not being considered. Accuracies = [(30.85,80.31),(42.96,91.53),(42.19,90.62)\n",
      "feature_select_dropout Trial 1: Feature at index 1 not being considered. Accuracies = [(47.38,89.46),(43.78,82.76),(50.00,94.38)\n",
      "feature_select_dropout Trial 2: Feature at index 2 not being considered. Accuracies = [(49.69,91.23),(47.24,89.39),(70.62,96.88)\n",
      "feature_select_dropout Trial 3: Feature at index 3 not being considered. Accuracies = [(44.31,88.85),(46.73,90.31),(60.31,95.62)\n",
      "feature_select_dropout Trial 4: Feature at index 4 not being considered. Accuracies = [(55.31,93.38),(54.08,93.57),(70.00,97.19)\n",
      "feature_select_dropout Trial 5: Feature at index 5 not being considered. Accuracies = [(25.08,62.08),(27.96,64.08),(50.31,94.38)\n",
      "feature_select_dropout Trial 6: Feature at index 6 not being considered. Accuracies = [(46.08,91.77),(48.16,93.47),(35.94,93.44)\n",
      "feature_select_dropout Trial 7: Feature at index 7 not being considered. Accuracies = [(40.54,89.85),(39.90,89.18),(54.37,92.19)\n",
      "feature_select_dropout Trial 8: Feature at index 8 not being considered. Accuracies = [(52.46,92.46),(50.20,92.86),(35.94,87.50)\n",
      "feature_select_dropout Trial 9: Feature at index 9 not being considered. Accuracies = [(36.08,80.23),(51.63,91.73),(48.44,88.75)\n",
      "feature_select_dropout Trial 10: Feature at index 10 not being considered. Accuracies = [(30.54,76.69),(26.94,76.73),(29.69,65.00)\n",
      "Worst Trial for Combined Data Set Exact Accuracy = 5\n",
      "Worst Trial for White Wine Data Set Exact Accuracy = 10\n",
      "Worst Trial for Red Wine Data Set Exact Accuracy = 10\n",
      "Worst Trial for Combined Data Set T1 Accuracy = 5\n",
      "Worst Trial for White Wine Data Set T1 Accuracy = 10\n",
      "Worst Trial for Red Wine Data Set T1 Accuracy = 10\n",
      "Best Trial for Combined Data Set Exact Accuracy = 4\n",
      "Best Trial for White Wine Data Set Exact Accuracy = 4\n",
      "Best Trial for Red Wine Data Set Exact Accuracy = 2\n",
      "Best Trial for Combined Data Set T1 Accuracy = 4\n",
      "Best Trial for White Wine Data Set T1 Accuracy = 4\n",
      "Best Trial for Red Wine Data Set T1 Accuracy = 2\n"
     ]
    }
   ],
   "source": [
    "feature_select_dropout(optimal_models) # Run this to perform the feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb0480",
   "metadata": {},
   "source": [
    "### Feature Selection Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6472d",
   "metadata": {},
   "source": [
    "## Computational Experiment 2\n",
    "\n",
    "### Input Optimization (Gradient Ascent)\n",
    "\n",
    "Hypothesis: There is an optimal and least optimal input which would be rated by the neural network as a 10 and 0 respectively and maximize the activation of that particular output neuron. Because we found the most important input features for models x, y, z to be i, j, k, we suspect that these features will also be maximized or minimized in such an optimal input- however, perhaps it will be a value closer to that of other wines who scored a 10 or a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eed71810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define the new model\n",
    "# this model should have one parameter tensor: the input vector you are optimization\n",
    "# its `forward` function should apply the pretrained `WineQuality` model to this model's `optimized_input`\n",
    "\n",
    "class InputOptim(nn.Module):\n",
    "    def __init__(self, wine_model, input_shape=(11, )):\n",
    "        super().__init__()\n",
    "        self.wine_model = wine_model\n",
    "        self.optimized_input = torch.randn(1, input_shape[0], requires_grad=True) # initialize parameter tensor, should have requires_grad=True\n",
    "        #print(self.optimized_input.shape)\n",
    "        \n",
    "    def forward(self):\n",
    "        #print(f\"input_model.forward(): self.optimized_input = {self.optimized_input}\")\n",
    "        return self.wine_model.forward(self.optimized_input)\n",
    "\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.optimized_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d947eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 0th target.\n",
      "tensor([[-16.0979, -16.3812, -16.3121,   1.4890,   0.5404,   0.6147,   0.9020,\n",
      "           0.7785,  -1.4680,  -4.5000, -16.4111]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 0th target.\n",
      "tensor([[-11.1175, -11.0957, -10.8383,   0.4433,   0.4797,   0.4942,   0.5932,\n",
      "          -0.2989,   0.0750,  -0.5913, -10.7512]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 0th target.\n",
      "tensor([[-5.9999, -5.9584, -6.1994, -2.7344, -0.4993,  0.1866,  0.3915,  1.3648,\n",
      "          0.1880, -6.2090, -6.1093]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 1th target.\n",
      "tensor([[-16.2187, -16.4902, -16.4396,   1.5529,   0.6660,   0.5964,   0.9125,\n",
      "           0.7001,  -1.6213,  -4.5287, -16.5243]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 1th target.\n",
      "tensor([[-10.8206, -10.7999, -10.5373,   0.5583,   0.3833,   0.3787,   0.6763,\n",
      "          -0.0244,   0.0258,  -0.2657, -10.4652]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 1th target.\n",
      "tensor([[-9.7277, -9.1984, -9.7213, -6.8452, -3.4226, -0.1034,  2.3079,  2.1785,\n",
      "          1.0614, -9.6650, -9.9374]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 2th target.\n",
      "tensor([[-17.7320, -17.9652, -17.9230,   0.4896,   0.8476,   0.0656,   1.0392,\n",
      "           1.2902,  -0.5372,  -2.7340, -18.0175]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 2th target.\n",
      "tensor([[-13.5744, -13.6014, -13.2334,  -1.4318,   0.4535,   0.5604,   0.4122,\n",
      "           0.3498,   0.7541,   0.3794, -13.2830]], grad_fn=<MmBackward>)\n",
      "torch.Size([1, 11])\n",
      "Calculated optimal input for 2th target.\n",
      "tensor([[-10.3798,  -9.8496, -10.3963,  -7.4888,  -3.7488,   0.1683,   2.4411,\n",
      "           2.3474,   1.0683, -10.2682, -10.6027]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# next, train 11 `InputOptim` models, one for each output class (\"0\", \"1\", etc.)\n",
    "#targets = torch.arange(10).long()\n",
    "opt_stims = []\n",
    "\n",
    "n_epochs = 10000\n",
    "targets = [torch.tensor([0]), torch.tensor([10]), torch.tensor([9])]\n",
    "tidx = 0\n",
    "for t in targets:\n",
    "    for i in range(3):\n",
    "        model = optimal_models[i]\n",
    "        input_model = InputOptim(model)\n",
    "        optimizer = torch.optim.Adam(input_model.parameters(), lr=1e-3) # make sure this only optimizes the `input_model` parameters!\n",
    "        lossfxn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "        for epoch in range(n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = input_model.forward()\n",
    "\n",
    "            #loss = lossfxn(outputs, torch.unsqueeze(t, 0))\n",
    "            loss = lossfxn(outputs, t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "  \n",
    "        #print(f\"Optimal input for target {t}, model{i}: {input_model.optimized_input.detach().numpy()}\")\n",
    "        print(f\"Calculated optimal input for {tidx}th target.\")\n",
    "        print(model.forward(input_model.optimized_input.detach()))\n",
    "        opt_stims.append(input_model.optimized_input.detach().numpy())\n",
    "    tidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bfd4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.0, 30), (4.0, 216), (5.0, 2138), (6.0, 2836), (7.0, 1079), (8.0, 193), (9.0, 5)]\n"
     ]
    }
   ],
   "source": [
    "counts = {}\n",
    "for row in data_array:\n",
    "    label = row[11]\n",
    "    if label in counts:\n",
    "        counts[label] += 1\n",
    "    else:\n",
    "        counts[label] = 1\n",
    "print(sorted(counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a035c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
